{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from simCRN.multivariate_reg import read_eq_data_file\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.plots\n",
    "import tensorflow_docs.modeling\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import r2_score\n",
    "from hyperopt import hp\n",
    "from hyperopt import fmin, tpe, space_eval, Trials\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline model: Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ci_all_array, Am_array, Cmin, Cmax, Ai = read_eq_data_file('4-4-2-asym-AB-AC.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(Am_array, Ci_all_array, test_size=0.2, random_state=0)\n",
    "\n",
    "# Z normalizing\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_model = DecisionTreeRegressor(criterion=\"squared_error\", random_state=0)\n",
    "decision_tree_model.fit(X_train_scaled, y_train)\n",
    "y_hat_dt_train = decision_tree_model.predict(X_train_scaled)\n",
    "y_hat_dt_test = decision_tree_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MAE on the training data for C₁ is 7.89e-09\n",
      "The MAE on the training data for C₂ is 7.8e-09\n",
      "The MAE on the test data for C₁ is 2e-08\n",
      "The MAE on the test data for C₂ is 2.13e-08\n",
      "\n",
      "The average value of C₁ is 7.61e-07\n",
      "The average value of C₂ is 7.5e-07\n",
      "\n",
      "For the test data, MAE/mean for C₁ is 0.0263\n",
      "For the test data, MAE/mean for C₂ is 0.0284\n"
     ]
    }
   ],
   "source": [
    "dt_train_mae = mae(y_train, y_hat_dt_train, multioutput='raw_values')\n",
    "dt_test_mae = mae(y_test, y_hat_dt_test, multioutput='raw_values')\n",
    "\n",
    "print(f'The MAE on the training data for C₁ is {dt_train_mae[0]:.3}') # 3 significant figures\n",
    "print(f'The MAE on the training data for C₂ is {dt_train_mae[1]:.3}')\n",
    "print(f'The MAE on the test data for C₁ is {dt_test_mae[0]:.3}')\n",
    "print(f'The MAE on the test data for C₂ is {dt_test_mae[1]:.3}')\n",
    "\n",
    "print() # new line\n",
    "\n",
    "# Contextualizing with the mean of C₁ and C₂\n",
    "means = np.mean(Ci_all_array, axis=0)\n",
    "print(f'The average value of C₁ is {means[0]:.3}')\n",
    "print(f'The average value of C₂ is {means[1]:.3}')\n",
    "\n",
    "print() # new line\n",
    "\n",
    "print(f'For the test data, MAE/mean for C₁ is {dt_test_mae[0]/means[0]:.3}')\n",
    "print(f'For the test data, MAE/mean for C₂ is {dt_test_mae[1]/means[1]:.3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE on the training data for C₁ is 1.03e-08\n",
      "The RMSE on the training data for C₂ is 1.02e-08\n",
      "The RMSE on the test data for C₁ is 2.64e-08\n",
      "The RMSE on the test data for C₂ is 2.91e-08\n",
      "\n",
      "The average value of C₁ is 7.61e-07\n",
      "The average value of C₂ is 7.5e-07\n",
      "\n",
      "For the test data, RMSE/mean for C₁ is 0.0348\n",
      "For the test data, RMSE/mean for C₂ is 0.0389\n"
     ]
    }
   ],
   "source": [
    "dt_train_mse = mse(y_train, y_hat_dt_train, multioutput='raw_values')\n",
    "dt_test_mse = mse(y_test, y_hat_dt_test, multioutput='raw_values')\n",
    "dt_train_rmse = np.sqrt(dt_train_mse)\n",
    "dt_test_rmse = np.sqrt(dt_test_mse)\n",
    "\n",
    "print(f'The RMSE on the training data for C₁ is {dt_train_rmse[0]:.3}') # 3 significant figures\n",
    "print(f'The RMSE on the training data for C₂ is {dt_train_rmse[1]:.3}')\n",
    "print(f'The RMSE on the test data for C₁ is {dt_test_rmse[0]:.3}')\n",
    "print(f'The RMSE on the test data for C₂ is {dt_test_rmse[1]:.3}')\n",
    "\n",
    "print() # new line\n",
    "\n",
    "# Contextualizing with the mean of C₁ and C₂\n",
    "print(f'The average value of C₁ is {means[0]:.3}')\n",
    "print(f'The average value of C₂ is {means[1]:.3}')\n",
    "\n",
    "print() # new line\n",
    "\n",
    "print(f'For the test data, RMSE/mean for C₁ is {dt_test_rmse[0]/means[0]:.3}')\n",
    "print(f'For the test data, RMSE/mean for C₂ is {dt_test_rmse[1]/means[1]:.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a sense of appropriate ccp_alpha values for minimal cost complexity pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00000000e+00 2.25979950e-19 2.80596137e-19 2.83456633e-19\n",
      " 2.87232053e-19 2.97634676e-19 2.98179810e-19 3.05670823e-19\n",
      " 3.10142741e-19 3.12294255e-19 3.14632248e-19 3.21484030e-19\n",
      " 3.22019913e-19 3.27842311e-19 3.35692487e-19 3.37895020e-19\n",
      " 3.38092661e-19 3.40415422e-19 3.51083746e-19 3.51599462e-19\n",
      " 3.52768254e-19 3.55379013e-19 3.55684061e-19 3.58714794e-19\n",
      " 3.69615093e-19 3.74778766e-19 3.79251160e-19 3.82124384e-19\n",
      " 3.82754046e-19 3.82772350e-19 3.83589113e-19 3.84149090e-19\n",
      " 3.86822951e-19 3.87158767e-19 3.90118869e-19 3.98807457e-19\n",
      " 4.01359503e-19 4.02027740e-19 4.02226567e-19 4.02853514e-19\n",
      " 4.04868060e-19 4.08106464e-19 4.09044021e-19 4.11005777e-19\n",
      " 4.12205149e-19 4.18181471e-19 4.18222174e-19 4.18427113e-19\n",
      " 4.23991160e-19 4.24573782e-19 4.25797530e-19 4.27281529e-19\n",
      " 4.27349379e-19 4.27643079e-19 4.36032848e-19 4.43473134e-19\n",
      " 4.46773958e-19 4.47498608e-19 4.49582161e-19 4.49905718e-19\n",
      " 4.60105083e-19 4.63526456e-19 4.63760043e-19 4.64613040e-19\n",
      " 4.65306810e-19 4.66076540e-19 4.66886244e-19 4.67052215e-19\n",
      " 4.68448324e-19 4.69118992e-19 4.71070549e-19 4.71529681e-19\n",
      " 4.72505875e-19 4.73829503e-19 4.78286972e-19 4.82258456e-19\n",
      " 4.85011181e-19 4.86191503e-19 4.87490847e-19 4.87604721e-19\n",
      " 4.90033463e-19 4.96045069e-19 5.00477839e-19 5.00731439e-19\n",
      " 5.04857878e-19 5.10119500e-19 5.11195358e-19 5.12042998e-19\n",
      " 5.17803683e-19 5.20521507e-19 5.22517238e-19 5.26368470e-19\n",
      " 5.30331870e-19 5.30698456e-19 5.31362616e-19 5.31502221e-19\n",
      " 5.36466214e-19 5.36604223e-19 5.38899825e-19 5.38971944e-19\n",
      " 5.39000353e-19 5.39593040e-19 5.44081949e-19 5.44125119e-19\n",
      " 5.44567016e-19 5.44857124e-19 5.45639907e-19 5.46459693e-19\n",
      " 5.53611138e-19 5.54338890e-19 5.59640728e-19 5.62711525e-19\n",
      " 5.65060843e-19 5.67667014e-19 5.69675524e-19 5.72532628e-19\n",
      " 5.73374754e-19 5.73584775e-19 5.73588054e-19 5.77559938e-19\n",
      " 5.87275956e-19 5.88749781e-19 5.89355761e-19 5.90015047e-19\n",
      " 5.90535862e-19 5.90660161e-19 6.00734532e-19 6.03317145e-19\n",
      " 6.19209714e-19 6.22334932e-19 6.27788984e-19 6.28029067e-19\n",
      " 6.31953716e-19 6.32460898e-19 6.32949096e-19 6.34597992e-19\n",
      " 6.36020026e-19 6.36526434e-19 6.43409536e-19 6.44232898e-19\n",
      " 6.46204548e-19 6.48802223e-19 6.50209431e-19 6.50634299e-19\n",
      " 6.50889151e-19 6.54165411e-19 6.57599421e-19 6.62581029e-19\n",
      " 6.68217951e-19 6.69314066e-19 6.69836205e-19 6.70225477e-19\n",
      " 6.76939154e-19 6.77392862e-19 6.80538934e-19 6.84187062e-19\n",
      " 6.84604722e-19 6.89316404e-19 6.90342119e-19 6.93949092e-19\n",
      " 7.15336127e-19 7.16036535e-19 7.21733577e-19 7.23163471e-19\n",
      " 7.28131219e-19 7.29150710e-19 7.40513621e-19 7.40606486e-19\n",
      " 7.40911415e-19 7.42524227e-19 7.42672071e-19 7.50111794e-19\n",
      " 7.53202230e-19 7.56734853e-19 7.58658104e-19 7.59255721e-19\n",
      " 7.70360855e-19 7.72003684e-19 7.73750554e-19 7.77948593e-19\n",
      " 7.78260071e-19 7.81282841e-19 7.84331683e-19 7.91100007e-19\n",
      " 7.92196958e-19 7.93487719e-19 8.02763486e-19 8.04591067e-19\n",
      " 8.05188534e-19 8.10210185e-19 8.18040603e-19 8.22085931e-19\n",
      " 8.22534468e-19 8.25522567e-19 8.25817988e-19 8.27546546e-19\n",
      " 8.34342077e-19 8.43317830e-19 8.44487663e-19 8.49072115e-19\n",
      " 8.50491332e-19 8.59296153e-19 8.62970417e-19 8.68645591e-19\n",
      " 8.69224137e-19 8.73273648e-19 8.75218817e-19 8.84686351e-19\n",
      " 8.90826527e-19 8.93183298e-19 8.93214420e-19 8.96351827e-19\n",
      " 8.98167951e-19 9.03429551e-19 9.06156288e-19 9.07409235e-19\n",
      " 9.13335647e-19 9.19105318e-19 9.21326051e-19 9.22489307e-19\n",
      " 9.22720933e-19 9.25834743e-19 9.33310927e-19 9.42911345e-19\n",
      " 9.45551315e-19 9.53920808e-19 9.58858004e-19 9.62537529e-19\n",
      " 9.81347213e-19 9.82766559e-19 9.84383829e-19 9.88943086e-19\n",
      " 1.00925438e-18 1.01267735e-18 1.02959151e-18 1.03008619e-18\n",
      " 1.03577750e-18 1.04466982e-18 1.04563329e-18 1.05300430e-18\n",
      " 1.05525084e-18 1.05926947e-18 1.06221943e-18 1.06261966e-18\n",
      " 1.06285149e-18 1.06301581e-18 1.06469620e-18 1.06982397e-18\n",
      " 1.07390269e-18 1.08081024e-18 1.08235972e-18 1.09138336e-18\n",
      " 1.09174186e-18 1.09677333e-18 1.09856342e-18 1.09894139e-18\n",
      " 1.10299271e-18 1.10494246e-18 1.10555609e-18 1.10742862e-18\n",
      " 1.10808290e-18 1.11360718e-18 1.11800643e-18 1.11978872e-18\n",
      " 1.13346026e-18 1.13626843e-18 1.14084497e-18 1.14464615e-18\n",
      " 1.15174679e-18 1.16498775e-18 1.16703090e-18 1.16803543e-18\n",
      " 1.17153042e-18 1.18317094e-18 1.18814972e-18 1.19232800e-18\n",
      " 1.20372217e-18 1.20822816e-18 1.21217787e-18 1.21246634e-18\n",
      " 1.22482506e-18 1.23439668e-18 1.23576741e-18 1.24406321e-18\n",
      " 1.24438974e-18 1.24732177e-18 1.24869049e-18 1.24990436e-18\n",
      " 1.25043268e-18 1.25374386e-18 1.25495636e-18 1.26393817e-18\n",
      " 1.26961062e-18 1.28988535e-18 1.29025724e-18 1.29091959e-18\n",
      " 1.29372574e-18 1.29501297e-18 1.30407150e-18 1.31947766e-18\n",
      " 1.32835242e-18 1.33293919e-18 1.34177080e-18 1.35351956e-18\n",
      " 1.35716666e-18 1.36767399e-18 1.37722222e-18 1.37857113e-18\n",
      " 1.38723529e-18 1.42317783e-18 1.44516864e-18 1.46399484e-18\n",
      " 1.49214647e-18 1.49301478e-18 1.49326181e-18 1.50277681e-18\n",
      " 1.50587628e-18 1.51719333e-18 1.52041676e-18 1.52604721e-18\n",
      " 1.54135827e-18 1.54460584e-18 1.56445004e-18 1.56564595e-18\n",
      " 1.57231060e-18 1.57395092e-18 1.57411290e-18 1.57469940e-18\n",
      " 1.58517405e-18 1.59004335e-18 1.59564836e-18 1.59838107e-18\n",
      " 1.60126413e-18 1.62121234e-18 1.62155009e-18 1.62164892e-18\n",
      " 1.62746496e-18 1.62884689e-18 1.63280653e-18 1.63683556e-18\n",
      " 1.65039552e-18 1.66797591e-18 1.70494539e-18 1.70904508e-18\n",
      " 1.72230399e-18 1.74617316e-18 1.76399429e-18 1.76945809e-18\n",
      " 1.78555276e-18 1.78631802e-18 1.79020039e-18 1.79560068e-18\n",
      " 1.80086192e-18 1.83518256e-18 1.84566759e-18 1.85569298e-18\n",
      " 1.86958493e-18 1.87644630e-18 1.88315611e-18 1.89221420e-18\n",
      " 1.89737636e-18 1.93674173e-18 1.93689195e-18 1.95427391e-18\n",
      " 1.98270351e-18 2.01555826e-18 2.04128320e-18 2.04944186e-18\n",
      " 2.07124447e-18 2.09645646e-18 2.11285697e-18 2.12697954e-18\n",
      " 2.16061654e-18 2.19887056e-18 2.22824483e-18 2.23346337e-18\n",
      " 2.24725212e-18 2.26580178e-18 2.27811847e-18 2.27877770e-18\n",
      " 2.28489900e-18 2.30182954e-18 2.32084703e-18 2.33162943e-18\n",
      " 2.37065801e-18 2.37996619e-18 2.40591457e-18 2.43007566e-18\n",
      " 2.46028933e-18 2.49294115e-18 2.49850437e-18 2.50314271e-18\n",
      " 2.51348729e-18 2.57317806e-18 2.59457297e-18 2.61217016e-18\n",
      " 2.62871220e-18 2.71275975e-18 2.76042168e-18 2.76541395e-18\n",
      " 2.76549682e-18 2.86195851e-18 2.86417879e-18 2.90359939e-18\n",
      " 2.90691385e-18 2.94789951e-18 2.94824311e-18 2.95402449e-18\n",
      " 2.98829017e-18 2.99783953e-18 3.01665585e-18 3.04059174e-18\n",
      " 3.15013307e-18 3.15870015e-18 3.21098717e-18 3.23936421e-18\n",
      " 3.26081686e-18 3.31768992e-18 3.40345365e-18 3.48315927e-18\n",
      " 3.54221580e-18 3.55912435e-18 3.57223487e-18 3.60952847e-18\n",
      " 3.65693475e-18 3.66957913e-18 3.68682777e-18 3.95483540e-18\n",
      " 4.00163690e-18 4.03718091e-18 4.10734403e-18 4.12441287e-18\n",
      " 4.25128330e-18 4.28847243e-18 4.38611062e-18 4.51355163e-18\n",
      " 4.58886274e-18 4.67792092e-18 4.77136690e-18 4.79701729e-18\n",
      " 4.93155169e-18 4.94320257e-18 5.02370523e-18 5.05195583e-18\n",
      " 5.08387232e-18 5.23038918e-18 5.28024771e-18 5.39302958e-18\n",
      " 5.47057210e-18 5.50397282e-18 5.69074472e-18 5.97541692e-18\n",
      " 5.98500186e-18 6.00435133e-18 6.09727565e-18 6.24550419e-18\n",
      " 6.27465806e-18 6.41341263e-18 6.41819258e-18 6.52152748e-18\n",
      " 6.53701938e-18 6.70934496e-18 6.75778082e-18 6.78169843e-18\n",
      " 6.84169945e-18 6.90475389e-18 6.94773889e-18 6.95169632e-18\n",
      " 7.03584981e-18 7.04132391e-18 7.09680041e-18 7.13741494e-18\n",
      " 7.16531683e-18 7.17910055e-18 7.20320160e-18 7.21119241e-18\n",
      " 7.26180047e-18 7.29950106e-18 7.41008194e-18 7.46232281e-18\n",
      " 7.46635976e-18 7.67078008e-18 7.76865621e-18 7.80907457e-18\n",
      " 7.82855210e-18 7.87444820e-18 7.89551176e-18 7.92139273e-18\n",
      " 7.93542002e-18 7.96165006e-18 7.98160907e-18 8.09591635e-18\n",
      " 8.21177894e-18 8.33500440e-18 8.33916334e-18 8.35544247e-18\n",
      " 8.53751846e-18 8.66134433e-18 8.74284438e-18 8.80817103e-18\n",
      " 8.83186671e-18 8.84663349e-18 8.84948926e-18 8.90845583e-18\n",
      " 8.93835562e-18 9.14649550e-18 9.19983939e-18 9.20561075e-18\n",
      " 9.32584525e-18 9.37049486e-18 9.46673404e-18 9.50333773e-18\n",
      " 9.50650662e-18 9.52245210e-18 9.57000794e-18 9.65901461e-18\n",
      " 9.69159208e-18 9.75816855e-18 1.01342208e-17 1.01403024e-17\n",
      " 1.01533146e-17 1.02000961e-17 1.02566225e-17 1.02839313e-17\n",
      " 1.02884994e-17 1.03871456e-17 1.08712106e-17 1.09394581e-17\n",
      " 1.10905647e-17 1.12008968e-17 1.12411505e-17 1.13561939e-17\n",
      " 1.13993446e-17 1.24567963e-17 1.25040974e-17 1.28773501e-17\n",
      " 1.29429028e-17 1.30928160e-17 1.33401085e-17 1.36134720e-17\n",
      " 1.36230945e-17 1.39547201e-17 1.40520299e-17 1.49296755e-17\n",
      " 1.49857265e-17 1.58063619e-17 1.60115866e-17 1.60994649e-17\n",
      " 1.62568024e-17 1.62700737e-17 1.63631504e-17 1.65114735e-17\n",
      " 1.67461001e-17 1.68642750e-17 1.69312479e-17 1.70568937e-17\n",
      " 1.73066568e-17 1.74614684e-17 1.77270833e-17 1.78157682e-17\n",
      " 1.79095481e-17 1.79186611e-17 1.79898217e-17 1.81920093e-17\n",
      " 1.84341937e-17 1.85729722e-17 1.85881711e-17 1.89923943e-17\n",
      " 1.94766793e-17 2.00389184e-17 2.00572481e-17 2.06367109e-17\n",
      " 2.07945143e-17 2.08781094e-17 2.12816504e-17 2.12921345e-17\n",
      " 2.18609831e-17 2.25371753e-17 2.37711106e-17 2.39013604e-17\n",
      " 2.39850441e-17 2.48110143e-17 2.60683906e-17 2.79137024e-17\n",
      " 2.81255036e-17 2.83953498e-17 2.86916011e-17 2.96518430e-17\n",
      " 2.98834049e-17 3.01054175e-17 3.01164382e-17 3.07541644e-17\n",
      " 3.21612154e-17 3.25831128e-17 3.32781151e-17 3.52484708e-17\n",
      " 3.55452362e-17 4.13504247e-17 4.40610807e-17 7.92302330e-17\n",
      " 8.32233431e-17 8.34615094e-17 8.44315481e-17 8.48513366e-17\n",
      " 9.07805817e-17 9.66615636e-17 1.03563017e-16 1.04577605e-16\n",
      " 1.20174906e-16 1.21200847e-16 1.21548258e-16 1.24143342e-16\n",
      " 1.25636440e-16 1.27509564e-16 1.28165756e-16 1.32524631e-16\n",
      " 1.33072201e-16 1.35504487e-16 1.35721999e-16 1.39001782e-16\n",
      " 1.44357989e-16 1.48909590e-16 1.55195286e-16 1.57119200e-16\n",
      " 1.63224497e-16 1.69099801e-16 1.71577248e-16 1.73543933e-16\n",
      " 1.74871967e-16 1.90506942e-16 1.98723357e-16 2.06381165e-16\n",
      " 2.40417946e-16 2.47433217e-16 2.54263485e-16 2.65104291e-16\n",
      " 2.86459307e-16 3.00208225e-16 3.05874480e-16 3.05899313e-16\n",
      " 3.20235947e-16 3.26528745e-16 3.30984016e-16 3.31741858e-16\n",
      " 3.32319553e-16 3.44290800e-16 3.95431270e-16 1.82926111e-15\n",
      " 1.89897604e-15 1.94117314e-15 2.02416974e-15 2.07472892e-15\n",
      " 2.16827392e-15 2.36437223e-15 2.37235452e-15 4.16924699e-15\n",
      " 4.27193121e-15 4.74350253e-15 5.02934346e-15 3.28834363e-14\n",
      " 3.61040847e-14 6.98954532e-14]\n"
     ]
    }
   ],
   "source": [
    "decision_tree_model_complexity = DecisionTreeRegressor(criterion=\"squared_error\", random_state=0)\n",
    "pruning_path = decision_tree_model_complexity.cost_complexity_pruning_path(X_train_scaled, y_train)\n",
    "ccp_alphas, impurities = pruning_path.ccp_alphas, pruning_path.impurities\n",
    "print(ccp_alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Total Impurity vs effective alpha for training set')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "ax.semilogx(ccp_alphas[:-1], impurities[:-1], marker=\".\", drawstyle=\"steps-post\")\n",
    "ax.set_xlabel(\"effective alpha\")\n",
    "ax.set_ylabel(\"total impurity of leaves\")\n",
    "ax.set_title(\"Total Impurity vs effective alpha for training set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_model = RandomForestRegressor(criterion=\"squared_error\", random_state=0)\n",
    "random_forest_model.fit(X_train_scaled, y_train)\n",
    "y_hat_train = random_forest_model.predict(X_train_scaled)\n",
    "y_hat_test = random_forest_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MAE on the training data for C₁ is 5.42e-09\n",
      "The MAE on the training data for C₂ is 5.66e-09\n",
      "The MAE on the test data for C₁ is 9.02e-09\n",
      "The MAE on the test data for C₂ is 9.6e-09\n",
      "\n",
      "The average value of C₁ is 7.61e-07\n",
      "The average value of C₂ is 7.5e-07\n",
      "\n",
      "For the test data, MAE/mean for C₁ is 0.0119\n",
      "For the test data, MAE/mean for C₂ is 0.0128\n"
     ]
    }
   ],
   "source": [
    "train_mae = mae(y_train, y_hat_train, multioutput='raw_values')\n",
    "test_mae = mae(y_test, y_hat_test, multioutput='raw_values')\n",
    "\n",
    "print(f'The MAE on the training data for C₁ is {train_mae[0]:.3}') # 3 significant figures\n",
    "print(f'The MAE on the training data for C₂ is {train_mae[1]:.3}')\n",
    "print(f'The MAE on the test data for C₁ is {test_mae[0]:.3}')\n",
    "print(f'The MAE on the test data for C₂ is {test_mae[1]:.3}')\n",
    "\n",
    "print() # new line\n",
    "\n",
    "# Contextualizing with the mean of C₁ and C₂\n",
    "means = np.mean(Ci_all_array, axis=0)\n",
    "print(f'The average value of C₁ is {means[0]:.3}')\n",
    "print(f'The average value of C₂ is {means[1]:.3}')\n",
    "\n",
    "print() # new line\n",
    "\n",
    "print(f'For the test data, MAE/mean for C₁ is {test_mae[0]/means[0]:.3}')\n",
    "print(f'For the test data, MAE/mean for C₂ is {test_mae[1]/means[1]:.3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE on the training data for C₁ is 6.92e-09\n",
      "The RMSE on the training data for C₂ is 7.24e-09\n",
      "The RMSE on the test data for C₁ is 1.32e-08\n",
      "The RMSE on the test data for C₂ is 1.25e-08\n",
      "\n",
      "The average value of C₁ is 7.61e-07\n",
      "The average value of C₂ is 7.5e-07\n",
      "\n",
      "For the test data, RMSE/mean for C₁ is 0.0174\n",
      "For the test data, RMSE/mean for C₂ is 0.0166\n"
     ]
    }
   ],
   "source": [
    "train_mse = mse(y_train, y_hat_train, multioutput='raw_values')\n",
    "test_mse = mse(y_test, y_hat_test, multioutput='raw_values')\n",
    "train_rmse = np.sqrt(train_mse)\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "\n",
    "print(f'The RMSE on the training data for C₁ is {train_rmse[0]:.3}') # 3 significant figures\n",
    "print(f'The RMSE on the training data for C₂ is {train_rmse[1]:.3}')\n",
    "print(f'The RMSE on the test data for C₁ is {test_rmse[0]:.3}')\n",
    "print(f'The RMSE on the test data for C₂ is {test_rmse[1]:.3}')\n",
    "\n",
    "print() # new line\n",
    "\n",
    "# Contextualizing with the mean of C₁ and C₂\n",
    "print(f'The average value of C₁ is {means[0]:.3}')\n",
    "print(f'The average value of C₂ is {means[1]:.3}')\n",
    "\n",
    "print() # new line\n",
    "\n",
    "print(f'For the test data, RMSE/mean for C₁ is {test_rmse[0]/means[0]:.3}')\n",
    "print(f'For the test data, RMSE/mean for C₂ is {test_rmse[1]/means[1]:.3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R² on the training data for C₁ is 1.0\n",
      "The R² on the training data for C₂ is 1.0\n",
      "The R² on the test data for C₁ is 0.999\n",
      "The R² on the test data for C₂ is 0.999\n"
     ]
    }
   ],
   "source": [
    "train_r2 = r2_score(y_train, y_hat_train, multioutput='raw_values')\n",
    "test_r2 = r2_score(y_test, y_hat_test, multioutput='raw_values')\n",
    "\n",
    "print(f'The R² on the training data for C₁ is {train_r2[0]:.3}') # 3 significant figures\n",
    "print(f'The R² on the training data for C₂ is {train_r2[1]:.3}')\n",
    "print(f'The R² on the test data for C₁ is {test_r2[0]:.3}')\n",
    "print(f'The R² on the test data for C₂ is {test_r2[1]:.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators_list = [20, 40, 80, 100, 160, 320, 640, 1280]\n",
    "min_samples_split_list = [2, 8, 10, 12, 24]\n",
    "max_depth_list = [2, 4, 8, 10, None]\n",
    "max_depth_list = [2, 4, 8, 10, None]\n",
    "parameter_space = {'n_estimators': hp.choice('n_estimators', n_estimators_list), \\\n",
    "                   'min_samples_split': hp.choice('min_samples_split', min_samples_split_list), \\\n",
    "                   'max_depth': hp.choice('max_depth', max_depth_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter Space Size: 200\n"
     ]
    }
   ],
   "source": [
    "print(f\"Parameter Space Size: {len(n_estimators_list)*len(min_samples_split_list)*len(max_depth_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "from hyperopt import fmin, tpe, space_eval, Trials\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_eval(args):\n",
    "\n",
    "    '''Take suggested arguments and perform model evaluation'''\n",
    "    \n",
    "    model = RandomForestRegressor(criterion=\"squared_error\", n_estimators=args['n_estimators'], \\\n",
    "                                  min_samples_split=args['min_samples_split'], max_depth=args['max_depth'])\n",
    "    \n",
    "    scores = cross_val_score(model, X_train_scaled, y=y_train, scoring='neg_mean_squared_error')\n",
    "\n",
    "    cv_score = np.mean(scores)\n",
    "\n",
    "    # return the negative of the CV score to ensure we maximize the negative MSE by minimizing the loss\n",
    "    return -cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start trials\n",
      "100%|██████████| 200/200 [38:53<00:00, 11.67s/trial, best loss: 1.6829057161124205e-16]\n"
     ]
    }
   ],
   "source": [
    "print(\"Start trials\") \n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(model_eval, parameter_space, algo=tpe.suggest, max_evals=200, trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter set: {'max_depth': 4, 'min_samples_split': 0, 'n_estimators': 6}\n",
      "Best loss from CV: 1.68e-16\n",
      "Best RMSE loss from CV: 1.3e-08\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameter set: {}\".format(best))\n",
    "print(\"Best loss from CV: {:.3}\".format(trials.best_trial['result']['loss']))\n",
    "print(\"Best RMSE loss from CV: {:.3}\".format(np.sqrt(trials.best_trial['result']['loss'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters\n",
      "n_estimators = 640\n",
      "max_depth = None\n",
      "min_samples_split = 2\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters\")\n",
    "print(f\"n_estimators = {n_estimators_list[best['n_estimators']]}\")\n",
    "print(f\"max_depth = {max_depth_list[best['max_depth']]}\")\n",
    "print(f\"min_samples_split = {min_samples_split_list[best['min_samples_split']]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_random_forest_model = RandomForestRegressor(criterion=\"squared_error\", \\\n",
    "                                                      n_estimators=n_estimators_list[best['n_estimators']], \n",
    "                                                      max_depth=max_depth_list[best['max_depth']], \\\n",
    "                                                      min_samples_split=min_samples_split_list[best['min_samples_split']])\n",
    "optimized_random_forest_model.fit(X_train_scaled, y_train)\n",
    "optimized_y_hat_train = optimized_random_forest_model.predict(X_train_scaled)\n",
    "optimized_y_hat_test = optimized_random_forest_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE on the training data for C₁ is 6.55e-09\n",
      "The RMSE on the training data for C₂ is 6.79e-09\n",
      "The RMSE on the test data for C₁ is 1.28e-08\n",
      "The RMSE on the test data for C₂ is 1.15e-08\n",
      "\n",
      "The average value of C₁ is 7.61e-07\n",
      "The average value of C₂ is 7.5e-07\n",
      "\n",
      "For the test data, RMSE/mean for C₁ is 0.0168\n",
      "For the test data, RMSE/mean for C₂ is 0.0153\n"
     ]
    }
   ],
   "source": [
    "optimized_train_mse = mse(y_train, optimized_y_hat_train, multioutput='raw_values')\n",
    "optimized_test_mse = mse(y_test, optimized_y_hat_test, multioutput='raw_values')\n",
    "optimized_train_rmse = np.sqrt(optimized_train_mse)\n",
    "optimized_test_rmse = np.sqrt(optimized_test_mse)\n",
    "\n",
    "print(f'The RMSE on the training data for C₁ is {optimized_train_rmse[0]:.3}') # 3 significant figures\n",
    "print(f'The RMSE on the training data for C₂ is {optimized_train_rmse[1]:.3}')\n",
    "print(f'The RMSE on the test data for C₁ is {optimized_test_rmse[0]:.3}')\n",
    "print(f'The RMSE on the test data for C₂ is {optimized_test_rmse[1]:.3}')\n",
    "\n",
    "print() # new line\n",
    "\n",
    "# Contextualizing with the mean of C₁ and C₂\n",
    "print(f'The average value of C₁ is {means[0]:.3}')\n",
    "print(f'The average value of C₂ is {means[1]:.3}')\n",
    "\n",
    "print() # new line\n",
    "\n",
    "print(f'For the test data, RMSE/mean for C₁ is {optimized_test_rmse[0]/means[0]:.3}')\n",
    "print(f'For the test data, RMSE/mean for C₂ is {optimized_test_rmse[1]/means[1]:.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reducing Dataset Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(Am_array, Ci_all_array, total_size, test_size, random_state):\n",
    "    # Reducing the dataset size\n",
    "    X_train_all, X_test_all, y_train_all, y_test_all = \\\n",
    "    train_test_split(Am_array, Ci_all_array, test_size=1-total_size, random_state=random_state)\n",
    "    \n",
    "    # Splitting into train and test\n",
    "    X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X_train_all, y_train_all, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    # Z normalizing\n",
    "    X_scaler = StandardScaler().fit(X_train)\n",
    "    X_train_scaled = X_scaler.transform(X_train)\n",
    "    X_test_scaled = X_scaler.transform(X_test)\n",
    "    return(X_train_scaled, X_test_scaled, X_test_all, y_train, y_test, y_test_all, X_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000.   500.   250.   125.    62.5]\n"
     ]
    }
   ],
   "source": [
    "# Reduced data set sizes\n",
    "data_set_sizes = 0.5 ** np.arange(1,6)\n",
    "print(data_set_sizes*2000)\n",
    "# Lists to store data and results in\n",
    "trials_list = []\n",
    "best_params_list = []\n",
    "X_train_scaled_list = []\n",
    "X_test_scaled_list = []\n",
    "X_test_all_list = []\n",
    "y_train_list = []\n",
    "y_test_list = []\n",
    "y_test_all_list = []\n",
    "X_scaler_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data set size: 1000.0\n",
      "100%|██████████| 200/200 [42:55<00:00, 12.88s/trial, best loss: 3.7694682028424574e-16]\n",
      "Best parameter set: {'max_depth': 4, 'min_samples_split': 0, 'n_estimators': 6}\n",
      "n_estimators = 640\n",
      "max_depth = None\n",
      "min_samples_split = 2\n",
      "Data set size: 500.0\n",
      "100%|██████████| 200/200 [49:25<00:00, 14.83s/trial, best loss: 7.429881825538787e-16] \n",
      "Best parameter set: {'max_depth': 4, 'min_samples_split': 0, 'n_estimators': 6}\n",
      "n_estimators = 640\n",
      "max_depth = None\n",
      "min_samples_split = 2\n",
      "Data set size: 250.0\n",
      "100%|██████████| 200/200 [26:42<00:00,  8.01s/trial, best loss: 1.5750579634999439e-15]\n",
      "Best parameter set: {'max_depth': 2, 'min_samples_split': 0, 'n_estimators': 5}\n",
      "n_estimators = 320\n",
      "max_depth = 8\n",
      "min_samples_split = 2\n",
      "Data set size: 125.0\n",
      "100%|██████████| 200/200 [20:06<00:00,  6.03s/trial, best loss: 4.470246816047388e-15]\n",
      "Best parameter set: {'max_depth': 3, 'min_samples_split': 0, 'n_estimators': 2}\n",
      "n_estimators = 80\n",
      "max_depth = 10\n",
      "min_samples_split = 2\n",
      "Data set size: 62.5\n",
      "100%|██████████| 200/200 [19:48<00:00,  5.94s/trial, best loss: 1.0145949026331597e-14]\n",
      "Best parameter set: {'max_depth': 2, 'min_samples_split': 0, 'n_estimators': 4}\n",
      "n_estimators = 160\n",
      "max_depth = 8\n",
      "min_samples_split = 2\n"
     ]
    }
   ],
   "source": [
    "# Iterate through smaller data set sizes\n",
    "for data_set_size in data_set_sizes:\n",
    "    print(f\"Data set size: {data_set_size*2000}\")\n",
    "    X_train_scaled, X_test_scaled, X_test_all, y_train, y_test, y_test_all, X_scaler = \\\n",
    "    prep_data(Am_array, Ci_all_array, data_set_size, 0.2, 0)\n",
    "    # Add data sets to lists\n",
    "    X_train_scaled_list.append(X_train_scaled)\n",
    "    X_test_scaled_list.append(X_test_scaled)\n",
    "    X_test_all_list.append(X_test_all)\n",
    "    y_train_list.append(y_train)\n",
    "    y_test_list.append(y_test)\n",
    "    y_test_all_list.append(y_test_all)\n",
    "    X_scaler_list.append(X_scaler)\n",
    "    def model_eval_data_set(args):\n",
    "\n",
    "        '''Take suggested arguments and perform model evaluation'''\n",
    "\n",
    "        model = RandomForestRegressor(criterion=\"squared_error\", n_estimators=args['n_estimators'], \\\n",
    "                                      min_samples_split=args['min_samples_split'], max_depth=args['max_depth'])\n",
    "\n",
    "        scores = cross_val_score(model, X_train_scaled, y=y_train, scoring='neg_mean_squared_error')\n",
    "\n",
    "        cv_score = np.mean(scores)\n",
    "\n",
    "        # return the negative of the CV score to ensure we maximize the negative MSE by minimizing the loss\n",
    "        return -cv_score\n",
    "    # Hyperparameter optimize\n",
    "    trials = Trials()\n",
    "    best = fmin(model_eval_data_set, parameter_space, algo=tpe.suggest, max_evals=200, trials=trials)\n",
    "    trials_list.append(trials)\n",
    "    best_params_list.append(best)\n",
    "    print(\"Best parameter set: {}\".format(best))\n",
    "    print(f\"n_estimators = {n_estimators_list[best['n_estimators']]}\")\n",
    "    print(f\"max_depth = {max_depth_list[best['max_depth']]}\")\n",
    "    print(f\"min_samples_split = {min_samples_split_list[best['min_samples_split']]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "python3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
