{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from simCRN.multivariate_reg import read_eq_data_file\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.plots\n",
    "import tensorflow_docs.modeling\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import r2_score\n",
    "from hyperopt import hp\n",
    "from hyperopt import fmin, tpe, space_eval, Trials\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline model: Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ci_all_array, Am_array, Cmin, Cmax, Ai = read_eq_data_file('4-4-2-semi-asym-AB-AC.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 4)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Am_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(Am_array, Ci_all_array, test_size=0.2, random_state=0)\n",
    "\n",
    "# Z normalizing\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_model = RandomForestRegressor(criterion=\"squared_error\", random_state=0)\n",
    "random_forest_model.fit(X_train_scaled, y_train)\n",
    "y_hat_train = random_forest_model.predict(X_train_scaled)\n",
    "y_hat_test = random_forest_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MAE on the training data for C₁ is 1.06e-08\n",
      "The MAE on the training data for C₂ is 1.03e-08\n",
      "The MAE on the test data for C₁ is 2.35e-08\n",
      "The MAE on the test data for C₂ is 2.39e-08\n",
      "\n",
      "The average value of C₁ is 1.51e-06\n",
      "The average value of C₂ is 1.48e-06\n",
      "\n",
      "For the test data, MAE/mean for C₁ is 0.0155\n",
      "For the test data, MAE/mean for C₂ is 0.0162\n"
     ]
    }
   ],
   "source": [
    "train_mae = mae(y_train, y_hat_train, multioutput='raw_values')\n",
    "test_mae = mae(y_test, y_hat_test, multioutput='raw_values')\n",
    "\n",
    "print(f'The MAE on the training data for C₁ is {train_mae[0]:.3}') # 3 significant figures\n",
    "print(f'The MAE on the training data for C₂ is {train_mae[1]:.3}')\n",
    "print(f'The MAE on the test data for C₁ is {test_mae[0]:.3}')\n",
    "print(f'The MAE on the test data for C₂ is {test_mae[1]:.3}')\n",
    "\n",
    "print() # new line\n",
    "\n",
    "# Contextualizing with the mean of C₁ and C₂\n",
    "means = np.mean(Ci_all_array, axis=0)\n",
    "print(f'The average value of C₁ is {means[0]:.3}')\n",
    "print(f'The average value of C₂ is {means[1]:.3}')\n",
    "\n",
    "print() # new line\n",
    "\n",
    "print(f'For the test data, MAE/mean for C₁ is {test_mae[0]/means[0]:.3}')\n",
    "print(f'For the test data, MAE/mean for C₂ is {test_mae[1]/means[1]:.3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE on the training data for C₁ is 1.38e-08\n",
      "The RMSE on the training data for C₂ is 1.35e-08\n",
      "The RMSE on the test data for C₁ is 3.05e-08\n",
      "The RMSE on the test data for C₂ is 3.12e-08\n",
      "\n",
      "The average value of C₁ is 1.51e-06\n",
      "The average value of C₂ is 1.48e-06\n",
      "\n",
      "For the test data, RMSE/mean for C₁ is 0.0201\n",
      "For the test data, RMSE/mean for C₂ is 0.0211\n"
     ]
    }
   ],
   "source": [
    "train_mse = mse(y_train, y_hat_train, multioutput='raw_values')\n",
    "test_mse = mse(y_test, y_hat_test, multioutput='raw_values')\n",
    "train_rmse = np.sqrt(train_mse)\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "\n",
    "print(f'The RMSE on the training data for C₁ is {train_rmse[0]:.3}') # 3 significant figures\n",
    "print(f'The RMSE on the training data for C₂ is {train_rmse[1]:.3}')\n",
    "print(f'The RMSE on the test data for C₁ is {test_rmse[0]:.3}')\n",
    "print(f'The RMSE on the test data for C₂ is {test_rmse[1]:.3}')\n",
    "\n",
    "print() # new line\n",
    "\n",
    "# Contextualizing with the mean of C₁ and C₂\n",
    "print(f'The average value of C₁ is {means[0]:.3}')\n",
    "print(f'The average value of C₂ is {means[1]:.3}')\n",
    "\n",
    "print() # new line\n",
    "\n",
    "print(f'For the test data, RMSE/mean for C₁ is {test_rmse[0]/means[0]:.3}')\n",
    "print(f'For the test data, RMSE/mean for C₂ is {test_rmse[1]/means[1]:.3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R² on the training data for C₁ is 1.0\n",
      "The R² on the training data for C₂ is 1.0\n",
      "The R² on the test data for C₁ is 0.999\n",
      "The R² on the test data for C₂ is 0.999\n"
     ]
    }
   ],
   "source": [
    "train_r2 = r2_score(y_train, y_hat_train, multioutput='raw_values')\n",
    "test_r2 = r2_score(y_test, y_hat_test, multioutput='raw_values')\n",
    "\n",
    "print(f'The R² on the training data for C₁ is {train_r2[0]:.3}') # 3 significant figures\n",
    "print(f'The R² on the training data for C₂ is {train_r2[1]:.3}')\n",
    "print(f'The R² on the test data for C₁ is {test_r2[0]:.3}')\n",
    "print(f'The R² on the test data for C₂ is {test_r2[1]:.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators_list = [20, 40, 80, 100, 160, 320, 640, 1280]\n",
    "min_samples_split_list = [2, 8, 10, 12, 24]\n",
    "max_depth_list = [2, 4, 8, 10, None]\n",
    "max_depth_list = [2, 4, 8, 10, None]\n",
    "parameter_space = {'n_estimators': hp.choice('n_estimators', n_estimators_list), \\\n",
    "                   'min_samples_split': hp.choice('min_samples_split', min_samples_split_list), \\\n",
    "                   'max_depth': hp.choice('max_depth', max_depth_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter Space Size: 200\n"
     ]
    }
   ],
   "source": [
    "print(f\"Parameter Space Size: {len(n_estimators_list)*len(min_samples_split_list)*len(max_depth_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "from hyperopt import fmin, tpe, space_eval, Trials\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_eval(args):\n",
    "\n",
    "    '''Take suggested arguments and perform model evaluation'''\n",
    "    \n",
    "    model = RandomForestRegressor(criterion=\"squared_error\", n_estimators=args['n_estimators'], \\\n",
    "                                  min_samples_split=args['min_samples_split'], max_depth=args['max_depth'])\n",
    "    \n",
    "    scores = cross_val_score(model, X_train_scaled, y=y_train, scoring='neg_mean_squared_error')\n",
    "\n",
    "    cv_score = np.mean(scores)\n",
    "\n",
    "    # return the negative of the CV score to ensure we maximize the negative MSE by minimizing the loss\n",
    "    return -cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start trials\n",
      "100%|██████████| 200/200 [36:59<00:00, 11.10s/trial, best loss: 1.352862235430332e-15]\n"
     ]
    }
   ],
   "source": [
    "print(\"Start trials\") \n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(model_eval, parameter_space, algo=tpe.suggest, max_evals=200, trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter set: {'max_depth': 4, 'min_samples_split': 0, 'n_estimators': 5}\n",
      "Best loss from CV: 1.35e-15\n",
      "Best RMSE loss from CV: 3.68e-08\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameter set: {}\".format(best))\n",
    "print(\"Best loss from CV: {:.3}\".format(trials.best_trial['result']['loss']))\n",
    "print(\"Best RMSE loss from CV: {:.3}\".format(np.sqrt(trials.best_trial['result']['loss'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters\n",
      "n_estimators = 320\n",
      "max_depth = None\n",
      "min_samples_split = 2\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters\")\n",
    "print(f\"n_estimators = {n_estimators_list[best['n_estimators']]}\")\n",
    "print(f\"max_depth = {max_depth_list[best['max_depth']]}\")\n",
    "print(f\"min_samples_split = {min_samples_split_list[best['min_samples_split']]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_random_forest_model = RandomForestRegressor(criterion=\"squared_error\", \\\n",
    "                                                      n_estimators=n_estimators_list[best['n_estimators']], \n",
    "                                                      max_depth=max_depth_list[best['max_depth']], \\\n",
    "                                                      min_samples_split=min_samples_split_list[best['min_samples_split']])\n",
    "optimized_random_forest_model.fit(X_train_scaled, y_train)\n",
    "optimized_y_hat_train = optimized_random_forest_model.predict(X_train_scaled)\n",
    "optimized_y_hat_test = optimized_random_forest_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE on the training data for C₁ is 1.28e-08\n",
      "The RMSE on the training data for C₂ is 1.24e-08\n",
      "The RMSE on the test data for C₁ is 2.94e-08\n",
      "The RMSE on the test data for C₂ is 2.99e-08\n",
      "\n",
      "The average value of C₁ is 1.51e-06\n",
      "The average value of C₂ is 1.48e-06\n",
      "\n",
      "For the test data, RMSE/mean for C₁ is 0.0194\n",
      "For the test data, RMSE/mean for C₂ is 0.0202\n"
     ]
    }
   ],
   "source": [
    "optimized_train_mse = mse(y_train, optimized_y_hat_train, multioutput='raw_values')\n",
    "optimized_test_mse = mse(y_test, optimized_y_hat_test, multioutput='raw_values')\n",
    "optimized_train_rmse = np.sqrt(optimized_train_mse)\n",
    "optimized_test_rmse = np.sqrt(optimized_test_mse)\n",
    "\n",
    "print(f'The RMSE on the training data for C₁ is {optimized_train_rmse[0]:.3}') # 3 significant figures\n",
    "print(f'The RMSE on the training data for C₂ is {optimized_train_rmse[1]:.3}')\n",
    "print(f'The RMSE on the test data for C₁ is {optimized_test_rmse[0]:.3}')\n",
    "print(f'The RMSE on the test data for C₂ is {optimized_test_rmse[1]:.3}')\n",
    "\n",
    "print() # new line\n",
    "\n",
    "# Contextualizing with the mean of C₁ and C₂\n",
    "print(f'The average value of C₁ is {means[0]:.3}')\n",
    "print(f'The average value of C₂ is {means[1]:.3}')\n",
    "\n",
    "print() # new line\n",
    "\n",
    "print(f'For the test data, RMSE/mean for C₁ is {optimized_test_rmse[0]/means[0]:.3}')\n",
    "print(f'For the test data, RMSE/mean for C₂ is {optimized_test_rmse[1]/means[1]:.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reducing Dataset Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(Am_array, Ci_all_array, total_size, test_size, random_state):\n",
    "    # Reducing the dataset size\n",
    "    X_train_all, X_test_all, y_train_all, y_test_all = \\\n",
    "    train_test_split(Am_array, Ci_all_array, test_size=1-total_size, random_state=random_state)\n",
    "    \n",
    "    # Splitting into train and test\n",
    "    X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X_train_all, y_train_all, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    # Z normalizing\n",
    "    X_scaler = StandardScaler().fit(X_train)\n",
    "    X_train_scaled = X_scaler.transform(X_train)\n",
    "    X_test_scaled = X_scaler.transform(X_test)\n",
    "    return(X_train_scaled, X_test_scaled, X_test_all, y_train, y_test, y_test_all, X_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000.   500.   250.   125.    62.5]\n"
     ]
    }
   ],
   "source": [
    "# Reduced data set sizes\n",
    "data_set_sizes = 0.5 ** np.arange(1,6)\n",
    "print(data_set_sizes*2000)\n",
    "# Lists to store data and results in\n",
    "trials_list = []\n",
    "best_params_list = []\n",
    "X_train_scaled_list = []\n",
    "X_test_scaled_list = []\n",
    "X_test_all_list = []\n",
    "y_train_list = []\n",
    "y_test_list = []\n",
    "y_test_all_list = []\n",
    "X_scaler_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data set size: 1000.0\n",
      "100%|██████████| 200/200 [1:06:57<00:00, 20.09s/trial, best loss: 3.2486420729425907e-15]\n",
      "Best parameter set: {'max_depth': 4, 'min_samples_split': 0, 'n_estimators': 7}\n",
      "n_estimators = 1280\n",
      "max_depth = None\n",
      "min_samples_split = 2\n",
      "Data set size: 500.0\n",
      "100%|██████████| 200/200 [43:33<00:00, 13.07s/trial, best loss: 6.883233265143629e-15]  \n",
      "Best parameter set: {'max_depth': 4, 'min_samples_split': 0, 'n_estimators': 3}\n",
      "n_estimators = 100\n",
      "max_depth = None\n",
      "min_samples_split = 2\n",
      "Data set size: 250.0\n",
      "100%|██████████| 200/200 [22:18<00:00,  6.69s/trial, best loss: 1.804728444186624e-14] \n",
      "Best parameter set: {'max_depth': 3, 'min_samples_split': 0, 'n_estimators': 5}\n",
      "n_estimators = 320\n",
      "max_depth = 10\n",
      "min_samples_split = 2\n",
      "Data set size: 125.0\n",
      "100%|██████████| 200/200 [15:55<00:00,  4.78s/trial, best loss: 3.125876063900783e-14] \n",
      "Best parameter set: {'max_depth': 2, 'min_samples_split': 0, 'n_estimators': 2}\n",
      "n_estimators = 80\n",
      "max_depth = 8\n",
      "min_samples_split = 2\n",
      "Data set size: 62.5\n",
      "100%|██████████| 200/200 [16:09<00:00,  4.85s/trial, best loss: 8.743558241323263e-14]\n",
      "Best parameter set: {'max_depth': 4, 'min_samples_split': 0, 'n_estimators': 4}\n",
      "n_estimators = 160\n",
      "max_depth = None\n",
      "min_samples_split = 2\n"
     ]
    }
   ],
   "source": [
    "# Iterate through smaller data set sizes\n",
    "for data_set_size in data_set_sizes:\n",
    "    print(f\"Data set size: {data_set_size*2000}\")\n",
    "    X_train_scaled, X_test_scaled, X_test_all, y_train, y_test, y_test_all, X_scaler = \\\n",
    "    prep_data(Am_array, Ci_all_array, data_set_size, 0.2, 0)\n",
    "    # Add data sets to lists\n",
    "    X_train_scaled_list.append(X_train_scaled)\n",
    "    X_test_scaled_list.append(X_test_scaled)\n",
    "    X_test_all_list.append(X_test_all)\n",
    "    y_train_list.append(y_train)\n",
    "    y_test_list.append(y_test)\n",
    "    y_test_all_list.append(y_test_all)\n",
    "    X_scaler_list.append(X_scaler)\n",
    "    def model_eval_data_set(args):\n",
    "\n",
    "        '''Take suggested arguments and perform model evaluation'''\n",
    "\n",
    "        model = RandomForestRegressor(criterion=\"squared_error\", n_estimators=args['n_estimators'], \\\n",
    "                                      min_samples_split=args['min_samples_split'], max_depth=args['max_depth'])\n",
    "\n",
    "        scores = cross_val_score(model, X_train_scaled, y=y_train, scoring='neg_mean_squared_error')\n",
    "\n",
    "        cv_score = np.mean(scores)\n",
    "\n",
    "        # return the negative of the CV score to ensure we maximize the negative MSE by minimizing the loss\n",
    "        return -cv_score\n",
    "    # Hyperparameter optimize\n",
    "    trials = Trials()\n",
    "    best = fmin(model_eval_data_set, parameter_space, algo=tpe.suggest, max_evals=200, trials=trials)\n",
    "    trials_list.append(trials)\n",
    "    best_params_list.append(best)\n",
    "    print(\"Best parameter set: {}\".format(best))\n",
    "    print(f\"n_estimators = {n_estimators_list[best['n_estimators']]}\")\n",
    "    print(f\"max_depth = {max_depth_list[best['max_depth']]}\")\n",
    "    print(f\"min_samples_split = {min_samples_split_list[best['min_samples_split']]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "python3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
